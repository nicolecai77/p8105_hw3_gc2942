---
title: "P8105_hw3_gc2942"
output: github_document
---
## Problem 1
```{r,include=FALSE}
library(tidyverse)
library(skimr)
library(patchwork)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r setup}
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")
library(skimr)
```

1. There are 134 aisles in the data set. Fresh vegetables aisle are the most items order from.
```{r}
instacart %>% 
  janitor::clean_names() %>% 
  group_by(aisle_id) %>% 
  summarize(n_obs = n())
```

```{r}

instacart %>% 
  janitor::clean_names() %>% 
  group_by(aisle) %>% 
  summarize(frequency = n()) %>% 
  mutate(aisle_rank = min_rank(desc(frequency))) %>% 
  filter(aisle_rank == 1)

```


2. Fresh fruit and fresh vegetables are the most popular aisles that people buy.
```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(frequency = n()) %>%
  filter(frequency > 10000)%>%
  arrange(frequency) %>% 
  ggplot(aes(x = aisle, y = frequency)) +
  geom_point(aes(color = aisle))+
  geom_blank()+
  labs(title = "number of items ordered in each aisle",
       x = "aisle with more than 10000 items",
       y = "number of items ordered") +
  viridis::scale_color_viridis(
    name ="aisle",
    discrete = TRUE
  ) +
  scale_x_discrete(label = abbreviate)
  
```


3. The most popular items in baking ingredients are light brown sugar,pure baking soda and cane sugar. The most popular items in dog food care are snack sticks chicken &rice recipe dag treats, organix chicken & brown rice recipe, and small dog biscuits. The most popualar items in packaged vegetable fruits are oganic baby spinach, organic raspberries, and organic blueberries.
```{r}
instacart %>% 
  select(aisle_id,aisle,product_name) %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle,product_name) %>% 
  summarize(number_of_times = n()) %>% 
  mutate(product_rank = min_rank(desc(number_of_times))) %>% 
  filter(product_rank %in% c(1,2,3)) %>% 
  arrange(aisle,product_rank) %>% 
  knitr::kable(digits = 0)
```

4.The mean hour of day for Coffee Ice Cream is highest in Tuesday.The mean hour of day for Pink Lady Apples is highest in Wednesday.
```{r,warning = FALSE}
instacart %>%   
  filter(product_name == c("Coffee Ice Cream","Pink Lady Apples"))%>%     
  group_by(product_name,order_dow) %>%  
  summarize(mean_hour = mean(order_hour_of_day)) %>%  
  mutate(order_dow = order_dow + 1) %>% 
  mutate(order_dow = lubridate::wday(order_dow, label = TRUE)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(digits = 2) 
  
```

There are `r nrow(instacart)` and `r ncol(instacart)` in the instacart data. 
The structure of data is shown by `str(instacart)` and gives us a preview of each column. The key variables are `r names(instacart)`. If we want some observations of data set, we can  look at `r skim(instacart)`.

## Problem 2

```{r}
brfss_df=brfss_smart2010 %>% 
  janitor::clean_names() %>%  
  filter(topic =="Overall Health") %>%  
  mutate(response = forcats::fct_relevel (response, "Poor", "Fair","Good","Very good","Excellent")) %>% 
  arrange(response)
  
```

```{r,warning=FALSE}
brfss_df %>% 
  filter(year == c("2002","2010")) %>% 
  group_by(year,locationabbr) %>%
  distinct(year,locationdesc) %>% 
  summarize(frequency = n()) %>% 
  filter(frequency >= 7)
```

1. In 2002, CT,MA,FL,NC,NJ,PA were observed at 7 or more locations. 
In 2010, CA,CO,FL,MA,MD,NC,NE,NJ,NY,OH,PA,SC,TX,WA were observed at 7 or more locations.

```{r,warning = FALSE}
brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year,locationabbr) %>% 
  summarize(data_value = mean(data_value)) %>% 
  ggplot(aes(x = year, y=data_value,color =locationabbr)) + geom_point() + geom_line() + labs(
    title = "Average Data Value Plot",
    x = "year",
    y ="mean",
    caption = "Data from the p8105 datasets package"
  ) +
  scale_color_hue(name = "locationabbr", h =c(100,300))
```

2. Average data value for excellence fluctuate across years and across different states.

```{r}
brfss_2006 = brfss_df %>% 
  filter(year == "2006", locationabbr == "NY") %>% 
  group_by(locationdesc,response) %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density() +
  labs(
   title = "Distribution Plot in 2006",
    x = "data_value") +
  theme(legend.position = "right")

brfss_2010 = brfss_df %>% 
  filter(year == "2010", locationabbr == "NY") %>% 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density() +
  labs(
   title = "Distribution Plot in 2010",
    x = "data_value",
    caption = "Data from the p8105 datasets package") +
    theme(legend.position = "none")
brfss_2006 + brfss_2010

```

3.Distribution plot among location in NY state in 2006 and in 2010 are slight different. For example, the distribution of fair has relatively higher median data value in 2006. However, the distribution of excellent has relatively higher median data value in 2010.

## Problem 3


```{r,warning=FALSE}
accel_data = read_csv("./accel_data.csv") %>% 
 janitor::clean_names() %>%
 drop_na() %>% 
pivot_longer(activity_1:activity_1440,
               names_to = "time",
               values_to = "count"
               ) %>%    
  mutate(weekends_weekday = ifelse(day %in% c("Sunday",   "Saturday"),"weekend","weekday")) %>% 
  mutate(day = as.factor(day)) %>% 
  separate(time,c("activity_","time"),"_") %>%
  select(-activity_) %>% 
  mutate(time=hms::as.hms (60 * as.numeric(time))) 
```
1. There are total `r nrow(accel_data)` and `r ncol(accel_data)`. The variables existing in the data set are `r names(accel_data)`. We add a new variable called weekend vs weekday into the data. The class of day has changed into factor. Time are organized in 24-hour time frame.

```{r}
accel_data %>% 
  group_by(day_id,weekends_weekday) %>%
  summarize(sum_count = sum(count)) %>% 
  knitr::kable(digits = 0)
```


2.The day_id 24 and  day_id 31 has the lowest total activity count; and those day are weekend. The total activity count shows a decreasing trend on weekend from week 1 to week 5.

```{r}
accel_data %>% 
  ggplot(aes(x = time, y = count, color = day)) +
  geom_point()+
  geom_line()+
  labs(
    title = "Accelerometer data plot for a 63 year-old male with BMI 25",
    x = "24-hour window",
    y ="activity count",
    caption = "Data from the p8105 datasets package"
  ) 
```


3.This man has a higher activity count at night around 8 pm on Friday and Wednesday.And he has a higher activity count at noon on Sunday.








